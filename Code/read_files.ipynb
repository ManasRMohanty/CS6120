{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_concepts_from_file(file_path,file_name,source):\n",
    "    \n",
    "    list_of_concepts = list()\n",
    "    \n",
    "    file = open(file_path, 'r',encoding=\"utf8\",errors = 'ignore') \n",
    "    Lines = file.readlines() \n",
    "    for line in Lines: \n",
    "        entry = line.strip()\n",
    "        regular_exp_con = 'c=\"(.*)\" ([0-9]*):([0-9]*) [0-9]*:([0-9]*)\\|\\|t=\"(.*)\"'\n",
    "        pattern_search = re.search(regular_exp_con, entry, re.IGNORECASE)\n",
    "\n",
    "        if pattern_search:\n",
    "            concept_dict = dict()\n",
    "            concept_dict['source'] = source\n",
    "            concept_dict['file_name'] = file_name \n",
    "            concept_dict['text'] = pattern_search.group(1)\n",
    "            concept_dict['line_number'] = int(pattern_search.group(2))\n",
    "            concept_dict['begin_word_num'] = int(pattern_search.group(3))\n",
    "            concept_dict['end_word_num'] = int(pattern_search.group(4))\n",
    "            concept_dict['concept_type'] = pattern_search.group(5)\n",
    "            list_of_concepts.append(concept_dict)\n",
    "    \n",
    "    return list_of_concepts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file_path = os.path.dirname(os.getcwd()) + r'\\Data\\concept_assertion_relation_training_data' \n",
    "beth_file_path = data_file_path + r'\\beth'\n",
    "partners_file_path = data_file_path + r'\\partners'\n",
    "\n",
    "list_of_all_concepts = list()\n",
    "\n",
    "for file in os.listdir(beth_file_path+r'\\concept'):\n",
    "    file_path = os.path.join(beth_file_path+r'\\concept', file)\n",
    "    list_of_all_concepts.extend(get_concepts_from_file(file_path,file.strip(\".con\"),'beth'))\n",
    "\n",
    "for file in os.listdir(partners_file_path+r'\\concept'):\n",
    "    file_path = os.path.join(partners_file_path+r'\\concept', file)\n",
    "    list_of_all_concepts.extend(get_concepts_from_file(file_path,file.strip(\".con\"),'partners'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "concept_df = pd.DataFrame(list_of_all_concepts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>file_name</th>\n",
       "      <th>text</th>\n",
       "      <th>line_number</th>\n",
       "      <th>begin_word_num</th>\n",
       "      <th>end_word_num</th>\n",
       "      <th>concept_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>beth</td>\n",
       "      <td>record-105</td>\n",
       "      <td>left basilar atelectasis</td>\n",
       "      <td>55</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>problem</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>beth</td>\n",
       "      <td>record-105</td>\n",
       "      <td>ventral hernia</td>\n",
       "      <td>143</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>problem</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>beth</td>\n",
       "      <td>record-105</td>\n",
       "      <td>htn</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>problem</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>beth</td>\n",
       "      <td>record-105</td>\n",
       "      <td>spontaneous echo contrast</td>\n",
       "      <td>68</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>problem</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>beth</td>\n",
       "      <td>record-105</td>\n",
       "      <td>cath</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  source   file_name                       text  line_number  begin_word_num  \\\n",
       "0   beth  record-105   left basilar atelectasis           55               6   \n",
       "1   beth  record-105             ventral hernia          143               1   \n",
       "2   beth  record-105                        htn           26               0   \n",
       "3   beth  record-105  spontaneous echo contrast           68               1   \n",
       "4   beth  record-105                       cath           21               0   \n",
       "\n",
       "   end_word_num concept_type  \n",
       "0             8      problem  \n",
       "1             2      problem  \n",
       "2             0      problem  \n",
       "3             3      problem  \n",
       "4             0         test  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concept_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "concept_type\n",
       "problem      7073\n",
       "test         4608\n",
       "treatment    4844\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concept_df.groupby(['concept_type']).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_assertions_from_file(file_path,file_name,source):\n",
    "    \n",
    "    list_of_assertions = list()\n",
    "    \n",
    "    file = open(file_path, 'r',encoding=\"utf8\",errors = 'ignore') \n",
    "    Lines = file.readlines() \n",
    "    \n",
    "    for line in Lines: \n",
    "        entry = line.strip()\n",
    "        regular_exp_con = 'c=\"(.*)\" ([0-9]*):([0-9]*) [0-9]*:([0-9]*)\\|\\|t=\".*\"\\|\\|a=\"(.*)\"'\n",
    "        pattern_search = re.search(regular_exp_con, entry, re.IGNORECASE)\n",
    "\n",
    "        if pattern_search:\n",
    "            assertion_dict = dict()\n",
    "            assertion_dict['source'] = source\n",
    "            assertion_dict['file_name'] = file_name \n",
    "            assertion_dict['text'] = pattern_search.group(1)\n",
    "            assertion_dict['line_number'] = int(pattern_search.group(2))\n",
    "            assertion_dict['begin_word_num'] = int(pattern_search.group(3))\n",
    "            assertion_dict['end_word_num'] = int(pattern_search.group(4))\n",
    "            assertion_dict['assertion_type'] = pattern_search.group(5)\n",
    "            list_of_assertions.append(assertion_dict)\n",
    "    \n",
    "    return list_of_assertions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_all_assertions = list()\n",
    "\n",
    "for file in os.listdir(beth_file_path+r'\\ast'):\n",
    "    file_path = os.path.join(beth_file_path+r'\\ast', file)\n",
    "    list_of_all_assertions.extend(get_assertions_from_file(file_path,file,'beth'))\n",
    "\n",
    "for file in os.listdir(partners_file_path+r'\\ast'):\n",
    "    file_path = os.path.join(partners_file_path+r'\\ast', file)\n",
    "    list_of_all_assertions.extend(get_assertions_from_file(file_path,file,'partners'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "assertion_df = pd.DataFrame(list_of_all_assertions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>file_name</th>\n",
       "      <th>text</th>\n",
       "      <th>line_number</th>\n",
       "      <th>begin_word_num</th>\n",
       "      <th>end_word_num</th>\n",
       "      <th>assertion_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>beth</td>\n",
       "      <td>record-105.ast</td>\n",
       "      <td>left basilar atelectasis</td>\n",
       "      <td>55</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>present</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>beth</td>\n",
       "      <td>record-105.ast</td>\n",
       "      <td>ventral hernia</td>\n",
       "      <td>143</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>present</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>beth</td>\n",
       "      <td>record-105.ast</td>\n",
       "      <td>htn</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>present</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>beth</td>\n",
       "      <td>record-105.ast</td>\n",
       "      <td>spontaneous echo contrast</td>\n",
       "      <td>68</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>absent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>beth</td>\n",
       "      <td>record-105.ast</td>\n",
       "      <td>80% lm lesion</td>\n",
       "      <td>21</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>present</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  source       file_name                       text  line_number  \\\n",
       "0   beth  record-105.ast   left basilar atelectasis           55   \n",
       "1   beth  record-105.ast             ventral hernia          143   \n",
       "2   beth  record-105.ast                        htn           26   \n",
       "3   beth  record-105.ast  spontaneous echo contrast           68   \n",
       "4   beth  record-105.ast              80% lm lesion           21   \n",
       "\n",
       "   begin_word_num  end_word_num assertion_type  \n",
       "0               6             8        present  \n",
       "1               1             2        present  \n",
       "2               0             0        present  \n",
       "3               1             3         absent  \n",
       "4               6             8        present  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assertion_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "assertion_type\n",
       "absent                          1596\n",
       "associated_with_someone_else      89\n",
       "conditional                       73\n",
       "hypothetical                     382\n",
       "possible                         309\n",
       "present                         4624\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assertion_df.groupby(['assertion_type']).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_relations_from_file(file_path,file_name,source):\n",
    "    \n",
    "    list_of_relations = list()\n",
    "    \n",
    "    file = open(file_path, 'r',encoding=\"utf8\",errors = 'ignore') \n",
    "    Lines = file.readlines() \n",
    "    \n",
    "    for line in Lines: \n",
    "        entry = line.strip()\n",
    "        regular_exp_con = 'c=\"(.*)\" ([0-9]*):([0-9]*) [0-9]*:([0-9]*)\\|\\|r=\"(.*)\"\\|\\|c=\"(.*)\" ([0-9]*):([0-9]*) [0-9]*:([0-9]*)'\n",
    "        pattern_search = re.search(regular_exp_con, entry, re.IGNORECASE)\n",
    "\n",
    "        if pattern_search:\n",
    "            relation_dict = dict()\n",
    "            relation_dict['source'] = source\n",
    "            relation_dict['file_name'] = file_name \n",
    "            relation_dict['from_text'] = pattern_search.group(1)\n",
    "            relation_dict['from_line_number'] = int(pattern_search.group(2))\n",
    "            relation_dict['from_begin_word_num'] = int(pattern_search.group(3))\n",
    "            relation_dict['from_end_word_num'] = int(pattern_search.group(4))\n",
    "            relation_dict['relation_type'] = pattern_search.group(5)\n",
    "            relation_dict['to_text'] = pattern_search.group(6)\n",
    "            relation_dict['to_line_number'] = int(pattern_search.group(7))\n",
    "            relation_dict['to_begin_word_num'] = int(pattern_search.group(8))\n",
    "            relation_dict['to_end_word_num'] = int(pattern_search.group(9))\n",
    "            list_of_relations.append(relation_dict)\n",
    "    \n",
    "    return list_of_relations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_all_relations = list()\n",
    "\n",
    "for file in os.listdir(beth_file_path+r'\\rel'):\n",
    "    file_path = os.path.join(beth_file_path+r'\\rel', file)\n",
    "    list_of_all_relations.extend(get_relations_from_file(file_path,file,'beth'))\n",
    "\n",
    "for file in os.listdir(partners_file_path+r'\\rel'):\n",
    "    file_path = os.path.join(partners_file_path+r'\\rel', file)\n",
    "    list_of_all_relations.extend(get_relations_from_file(file_path,file,'partners'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "relation_df = pd.DataFrame(list_of_all_relations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>file_name</th>\n",
       "      <th>from_text</th>\n",
       "      <th>from_line_number</th>\n",
       "      <th>from_begin_word_num</th>\n",
       "      <th>from_end_word_num</th>\n",
       "      <th>relation_type</th>\n",
       "      <th>to_text</th>\n",
       "      <th>to_line_number</th>\n",
       "      <th>to_begin_word_num</th>\n",
       "      <th>to_end_word_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>beth</td>\n",
       "      <td>record-105.rel</td>\n",
       "      <td>cath</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>TeRP</td>\n",
       "      <td>80% lm lesion</td>\n",
       "      <td>21</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>beth</td>\n",
       "      <td>record-105.rel</td>\n",
       "      <td>pefusion imaging</td>\n",
       "      <td>19</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>TeRP</td>\n",
       "      <td>perfusion defects</td>\n",
       "      <td>19</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>beth</td>\n",
       "      <td>record-105.rel</td>\n",
       "      <td>drugs</td>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>TrCP</td>\n",
       "      <td>known allergies</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>beth</td>\n",
       "      <td>record-105.rel</td>\n",
       "      <td>metal plate</td>\n",
       "      <td>26</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>TrAP</td>\n",
       "      <td>gsw</td>\n",
       "      <td>26</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>beth</td>\n",
       "      <td>record-105.rel</td>\n",
       "      <td>creams</td>\n",
       "      <td>145</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>TrNAP</td>\n",
       "      <td>any incisions</td>\n",
       "      <td>145</td>\n",
       "      <td>20</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  source       file_name         from_text  from_line_number  \\\n",
       "0   beth  record-105.rel              cath                21   \n",
       "1   beth  record-105.rel  pefusion imaging                19   \n",
       "2   beth  record-105.rel             drugs                12   \n",
       "3   beth  record-105.rel       metal plate                26   \n",
       "4   beth  record-105.rel            creams               145   \n",
       "\n",
       "   from_begin_word_num  from_end_word_num relation_type            to_text  \\\n",
       "0                    0                  0          TeRP      80% lm lesion   \n",
       "1                    6                  7          TeRP  perfusion defects   \n",
       "2                    8                  8          TrCP    known allergies   \n",
       "3                    7                  8          TrAP                gsw   \n",
       "4                   14                 14         TrNAP      any incisions   \n",
       "\n",
       "   to_line_number  to_begin_word_num  to_end_word_num  \n",
       "0              21                  6                8  \n",
       "1              19                 12               13  \n",
       "2              12                  5                6  \n",
       "3              26                 11               11  \n",
       "4             145                 20               21  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relation_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "relation_type\n",
       "PIP      755\n",
       "TeCP     166\n",
       "TeRP     993\n",
       "TrAP     885\n",
       "TrCP     184\n",
       "TrIP      51\n",
       "TrNAP     62\n",
       "TrWP      24\n",
       "dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relation_df.groupby(['relation_type']).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = r\"C:/Users/itsma/Documents/CS 6120 Project/Data/concept_assertion_relation_training_data/beth/txt/record-105.txt\"\n",
    "\n",
    "oFile = open(text, 'r')\n",
    "line = oFile.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "line.split(\"\\n\")[25].split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in tqdm(os.listdir(beth_file_path+r'\\txt')):\n",
    "    if(not file.endswith(\".txt\")):\n",
    "        continue\n",
    "    file_path = os.path.join(beth_file_path+r'\\txt', file)\n",
    "    file_name = file.strip(\".txt\")\n",
    "    oFile = open(file_path, 'r')\n",
    "    line = oFile.read()\n",
    "    all_lines = line.split(\"\\n\")\n",
    "    \n",
    "    file_concepts = concept_df[(concept_df['file_name']==file_name)&(concept_df['source']=='beth')]\n",
    "    \n",
    "    for index,row in file_concepts.iterrows():\n",
    "        words = all_lines[int(row['line_number'])-1].split()[int(row['begin_word_num']):int(row['end_word_num'])+1]\n",
    "        if(\" \".join(words).lower()!=row['text'].lower()):\n",
    "            print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-uncased', return_dict=True)\n",
    "\n",
    "inputs = tokenizer(\"Hello, my dog is cute\", return_tensors=\"pt\")\n",
    "outputs = model(**inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encodings = tokenizer.encode(\"Hello, my dog is cute\",add_special_tokens = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = torch.tensor(encodings).long().unsqueeze(0)\n",
    "        \n",
    "outputs = model(input_ids,token_type_ids=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(outputs[0][0][5].data.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from BERT_utility import BERT_utility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imp import reload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import BERT_utility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'BERT_utility' from 'C:\\\\Users\\\\itsma\\\\Documents\\\\CS 6120 Project\\\\CS6120\\\\Code\\\\BERT_utility.py'>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload(BERT_utility)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "utility = BERT_utility()\n",
    "#word_list = utility.process_string_finetune(line,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pos_dict(concept):\n",
    "    positions = dict()\n",
    "    \n",
    "    for index,row in concept.iterrows():\n",
    "        for i in range(row['begin_word_num'],row['end_word_num']+1):\n",
    "            positions[str(row['line_number'])+\":\"+str(i)] = row['concept_type']\n",
    "    \n",
    "    return positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 74/74 [06:11<00:00,  5.03s/it]\n"
     ]
    }
   ],
   "source": [
    "utility = BERT_utility()\n",
    "\n",
    "all_words_list = list()\n",
    "for file in tqdm(os.listdir(beth_file_path+r'\\txt')):\n",
    "    if(not file.endswith(\".txt\")):\n",
    "        continue\n",
    "    file_path = os.path.join(beth_file_path+r'\\txt', file)\n",
    "    file_name = file.strip(\".txt\")\n",
    "    oFile = open(file_path, 'r')\n",
    "    line = oFile.read()\n",
    "    all_lines = line.split(\"\\n\")\n",
    "    file_concepts = concept_df[(concept_df['file_name']==file_name)&(concept_df['source']=='beth')]\n",
    "    positions = create_pos_dict(file_concepts)\n",
    "    \n",
    "    word_list = utility.process_string_finetune(line,0)\n",
    "    \n",
    "    for entry in word_list:\n",
    "        key = str(entry['sentence_index'])+ \":\" +str(entry['word_index'])\n",
    "        if(key in positions):\n",
    "            entry.update({\"concept\":positions[key]})\n",
    "        else:\n",
    "            entry.update({\"concept\":\"blank\"})\n",
    "    \n",
    "    all_words_list.extend(word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 97/97 [05:27<00:00,  3.37s/it]\n"
     ]
    }
   ],
   "source": [
    "for file in tqdm(os.listdir(partners_file_path+r'\\txt')):\n",
    "    if(not file.endswith(\".txt\")):\n",
    "        continue\n",
    "    file_path = os.path.join(partners_file_path+r'\\txt', file)\n",
    "    file_name = file.strip(\".txt\")\n",
    "    oFile = open(file_path, 'r')\n",
    "    line = oFile.read()\n",
    "    all_lines = line.split(\"\\n\")\n",
    "    file_concepts = concept_df[(concept_df['file_name']==file_name)&(concept_df['source']=='partners')]\n",
    "    positions = create_pos_dict(file_concepts)\n",
    "    \n",
    "    word_list = utility.process_string_finetune(line,0)\n",
    "    \n",
    "    for entry in word_list:\n",
    "        key = str(entry['sentence_index'])+ \":\" +str(entry['word_index'])\n",
    "        if(key in positions):\n",
    "            entry.update({\"concept\":positions[key]})\n",
    "        else:\n",
    "            entry.update({\"concept\":\"blank\"})\n",
    "    \n",
    "    all_words_list.extend(word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "149351"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_words_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_df = pd.DataFrame(all_words_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'blank', 'problem', 'test', 'treatment'}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(list(words_df['concept']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dict = {\"a\":\"1\", \"b\":\"2\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(\"a\" in test_dict):\n",
    "    print(test_dict[\"a\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.vstack(list(words_df[\"keyword_vector\"]))                                \n",
    "y = words_df[\"concept\"]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\itsma\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression(random_state=0,solver=\"lbfgs\",max_iter=1000).fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9940475791926402"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_file_path = os.path.dirname(os.getcwd()) + r'\\Data\\reference_standard_for_test_data' \n",
    "\n",
    "list_of_all_test_concepts = list()\n",
    "\n",
    "for file in os.listdir(test_data_file_path+r'\\concepts'):\n",
    "    file_path = os.path.join(test_data_file_path+r'\\concepts', file)\n",
    "    list_of_all_test_concepts.extend(get_concepts_from_file(file_path,file.strip(\".con\"),'test_data'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_concept_df = pd.DataFrame(list_of_all_test_concepts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>file_name</th>\n",
       "      <th>text</th>\n",
       "      <th>line_number</th>\n",
       "      <th>begin_word_num</th>\n",
       "      <th>end_word_num</th>\n",
       "      <th>concept_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>test_data</td>\n",
       "      <td>0001</td>\n",
       "      <td>his home regimen</td>\n",
       "      <td>111</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>treatment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>test_data</td>\n",
       "      <td>0001</td>\n",
       "      <td>cad/chf</td>\n",
       "      <td>111</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>problem</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>test_data</td>\n",
       "      <td>0001</td>\n",
       "      <td>his acute gi bleed</td>\n",
       "      <td>111</td>\n",
       "      <td>20</td>\n",
       "      <td>23</td>\n",
       "      <td>problem</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>test_data</td>\n",
       "      <td>0001</td>\n",
       "      <td>basos</td>\n",
       "      <td>78</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>test_data</td>\n",
       "      <td>0001</td>\n",
       "      <td>biopsies</td>\n",
       "      <td>109</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      source file_name                text  line_number  begin_word_num  \\\n",
       "0  test_data      0001    his home regimen          111               8   \n",
       "1  test_data      0001             cad/chf          111               1   \n",
       "2  test_data      0001  his acute gi bleed          111              20   \n",
       "3  test_data      0001               basos           78               0   \n",
       "4  test_data      0001            biopsies          109               1   \n",
       "\n",
       "   end_word_num concept_type  \n",
       "0            10    treatment  \n",
       "1             1      problem  \n",
       "2            23      problem  \n",
       "3             0         test  \n",
       "4             1         test  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_concept_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 30/30 [02:20<00:00,  4.68s/it]\n"
     ]
    }
   ],
   "source": [
    "all_words_list_test = list()\n",
    "test_data_texts_path =  os.path.dirname(os.getcwd()) + r'\\Data\\test_data'\n",
    "for file in tqdm(os.listdir(test_data_texts_path)):\n",
    "    if(not file.endswith(\".txt\")):\n",
    "        continue\n",
    "    file_path = os.path.join(test_data_texts_path, file)\n",
    "    \n",
    "    file_name = file.strip(\".txt\")\n",
    "    \n",
    "    oFile = open(file_path, 'r')\n",
    "    \n",
    "    line = oFile.read()\n",
    "    \n",
    "    all_lines = line.split(\"\\n\")\n",
    "    \n",
    "    file_concepts = test_concept_df[(test_concept_df['file_name']==file_name)&(test_concept_df['source']=='test_data')]\n",
    "    \n",
    "    positions = create_pos_dict(file_concepts)\n",
    "    \n",
    "    word_list = utility.process_string_finetune(line,0)\n",
    "    \n",
    "    for entry in word_list:\n",
    "        key = str(entry['sentence_index'])+ \":\" +str(entry['word_index'])\n",
    "        if(key in positions):\n",
    "            entry.update({\"concept\":positions[key]})\n",
    "        else:\n",
    "            entry.update({\"concept\":\"blank\"})\n",
    "    \n",
    "    all_words_list_test.extend(word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_word_df = pd.DataFrame(all_words_list_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.vstack(list(test_word_df[\"keyword_vector\"]))                                \n",
    "y_test = test_word_df[\"concept\"]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9677156979290497"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = y_test\n",
    "y_predict = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['blank', 'problem', 'test', 'treatment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[23757,   187,   135,   151],\n",
       "       [  193,  3446,    17,    16],\n",
       "       [  143,     7,  1968,    26],\n",
       "       [  113,    32,    12,  1763]], dtype=int64)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_true,y_predict,labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9374012222907829"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_true, y_predict, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_map = {\"blank\":0,\"problem\":1,\"test\":2,\"treatment\":3}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding_list = list()\n",
    "label_list = list()\n",
    "utility = BERT_utility()\n",
    "\n",
    "for file in tqdm(os.listdir(beth_file_path+r'\\txt')):\n",
    "    if(not file.endswith(\".txt\")):\n",
    "        continue\n",
    "    file_path = os.path.join(beth_file_path+r'\\txt', file)\n",
    "    file_name = file.strip(\".txt\")\n",
    "    oFile = open(file_path, 'r')\n",
    "    line = oFile.read()\n",
    "    all_lines = line.split(\"\\n\")\n",
    "    file_concepts = concept_df[(concept_df['file_name']==file_name)&(concept_df['source']=='beth')]\n",
    "    positions = create_pos_dict(file_concepts)\n",
    "    \n",
    "    prior_sentence_index = -1\n",
    "    \n",
    "    word_list, encoding = utility.process_string_finetune(line,0)\n",
    "    \n",
    "    for i in range(len(all_lines)):\n",
    "        labels = [0] * len(encoding[i])\n",
    "        fil_word_list = [word for word in word_list if word[\"sentence_index\"]==i+1] \n",
    "        for entry in fil_word_list:\n",
    "            key = str(entry['sentence_index'])+ \":\" +str(entry['word_index'])\n",
    "            if(key in positions):\n",
    "                for token_position in entry[\"bert_token_positions\"]:\n",
    "                    labels[token_position] = class_map[positions[key]]\n",
    "        label_list.append(labels)\n",
    "    \n",
    "    encoding_list.extend(encoding)\n",
    "\n",
    "for file in tqdm(os.listdir(partners_file_path+r'\\txt')):\n",
    "    if(not file.endswith(\".txt\")):\n",
    "        continue\n",
    "    file_path = os.path.join(partners_file_path+r'\\txt', file)\n",
    "    file_name = file.strip(\".txt\")\n",
    "    oFile = open(file_path, 'r')\n",
    "    line = oFile.read()\n",
    "    all_lines = line.split(\"\\n\")\n",
    "    file_concepts = concept_df[(concept_df['file_name']==file_name)&(concept_df['source']=='partners')]\n",
    "    positions = create_pos_dict(file_concepts)\n",
    "    \n",
    "    prior_sentence_index = -1\n",
    "    \n",
    "    word_list, encoding = utility.process_string_finetune(line,0)\n",
    "    \n",
    "    for i in range(len(all_lines)):\n",
    "        labels = [0] * len(encoding[i])\n",
    "        \n",
    "        fil_word_list = [word for word in word_list if word[\"sentence_index\"]==i+1] \n",
    "        for entry in fil_word_list:\n",
    "            key = str(entry['sentence_index'])+ \":\" +str(entry['word_index'])\n",
    "            if(key in positions):\n",
    "                for token_position in entry[\"bert_token_positions\"]:\n",
    "                    labels[token_position] = class_map[positions[key]]\n",
    "        label_list.append(labels)\n",
    "    \n",
    "    encoding_list.extend(encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[0]*5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.convert_ids_to_tokens([101, 2381, 1997, 2556, 7355, 1024, 102])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_list[87]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding_list[87]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(encoding_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(encoding_list,open(\"C:/Users/itsma/Documents/CS 6120 Project/input_ids.pkl\",\"wb\"))\n",
    "pickle.dump(label_list,open(\"C:/Users/itsma/Documents/CS 6120 Project/label.pkl\",\"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finetuned_model = pickle.load(open(\"C:/Users/itsma/Documents/CS 6120 Project/CS6120/Model/finetuned_model.pkl\",\"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encodings = tokenizer.encode(\"Hello, my dog is cute\",add_special_tokens = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finetuned_model.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = torch.tensor(encodings).long().unsqueeze(0)\n",
    "        \n",
    "outputs = finetuned_model(input_ids,token_type_ids=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filt = [entry for entry in label_list if 3 in entry]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit ('base': conda)",
   "language": "python",
   "name": "python37464bitbasecondab189137550194d64ad595e9dd8ef8b75"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
